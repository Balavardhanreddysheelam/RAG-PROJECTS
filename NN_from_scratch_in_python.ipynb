{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlVNRa7VgVzvqvUl5fnIQh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Balavardhanreddysheelam/RAG-PROJECTS/blob/main/NN_from_scratch_in_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First importing all the necessary libraries\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1HIfjAoWrWce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "eNfLkpdAjzj5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the  data ready"
      ],
      "metadata": {
        "id": "gPJ9y61N8X6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784')\n",
        "\n",
        "print(mnist.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILQHFSUW97XY",
        "outputId": "751fb1d1-800b-413b-f981-379008483127"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = mnist.data\n",
        "labels = mnist.target"
      ],
      "metadata": {
        "id": "NaQ_0Z0b-wYy"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.random.choice(np.arange(data.shape[0]+1))\n",
        "n\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9OtthaW_CbK",
        "outputId": "dca2f18e-7209-4787-d4a0-caa7ab0e777d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(13956)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = data.iloc[n].values\n",
        "test_label = mnist.target.iloc[n]\n",
        "\n",
        "test_img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU6wjxA5ANQr",
        "outputId": "73accab9-20c3-4c04-aad4-fd5a46279990"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XoGXwNKSA2Qh",
        "outputId": "c2d2cf6e-ca53-420c-bbf7-ad949cde7a42"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_img.reshape(28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "H7tZNQ7gBDph",
        "outputId": "56c0d3c0-a243-4686-cd9d-5488a09fef71"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d292b6c2c90>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "setting up the weights along with one hidden layer"
      ],
      "metadata": {
        "id": "1urDdF6-DE7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = np.ones((784,4))*0.1\n",
        "z1 = np.dot(data,w1)\n",
        "z1.shape\n",
        "\n",
        "w2 = np.ones((4,10))\n",
        "z2 = np.dot(z1,w2)\n",
        "z2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2pa2QEUBVgu",
        "outputId": "e96a62b1-6445-4603-ed09-768eb2698084"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "defining the activation function"
      ],
      "metadata": {
        "id": "JVyx95sRDL0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z: np.ndarray) -> np.ndarray:\n",
        "    return 1.0 / (1.0 + np.exp(-z))\n",
        "def relu(z: np.ndarray) -> np.ndarray:\n",
        "    return np.maximum(0, z)\n",
        "def tanh(z: np.ndarray) -> np.ndarray:\n",
        "    return np.tanh(z)\n",
        "def leaky_relu(z: np.ndarray) -> np.ndarray:\n",
        "    return np.where(z > 0, z, z * 0.01)"
      ],
      "metadata": {
        "id": "hefT3AjrCqWi"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "used softmax for the output"
      ],
      "metadata": {
        "id": "vWyfKpqXEidU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z:np.ndarray) -> np.ndarray:\n",
        "  return np.exp(z)/np.sum(np.exp(z))\n"
      ],
      "metadata": {
        "id": "yfv94efADPeb"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalizing the vectors intput"
      ],
      "metadata": {
        "id": "EDk6m5b_FS-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x: np.ndarray) ->np.ndarray:\n",
        "  return(x-np.min(x))/(np.max(x)-np.min(x))"
      ],
      "metadata": {
        "id": "Jysj5AgnEHHu"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hot encoding because labels are in 1d so converting into 2d with multipying with identity matrix"
      ],
      "metadata": {
        "id": "II-bVyZ_FWFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(x:np.ndarray,num_labels:int) -> np.ndarray:\n",
        "  return np.eye(num_labels)[x]\n"
      ],
      "metadata": {
        "id": "7kBSR5edE2vD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "derivatives"
      ],
      "metadata": {
        "id": "cN0zGLLzGBUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def derivative(function_name: str, z: np.ndarray) -> np.ndarray:\n",
        "    if function_name == \"sigmoid\":\n",
        "        return sigmoid(z) * (1 - sigmoid(z))\n",
        "    if function_name == \"tanh\":\n",
        "        return 1 - np.square(tanh(z))\n",
        "    if function_name == \"relu\":\n",
        "        y = (z > 0) * 1\n",
        "        return y\n",
        "    if function_name == \"leaky_relu\":\n",
        "        return  np.where(z > 0, 1, 0.01)\n",
        "    return \"No such activation\""
      ],
      "metadata": {
        "id": "vJIHuG54FjzW"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN:\n",
        "  def __init__(self, X:np.ndarray, y:np.ndarray, X_test:np.ndarray, y_test:np.ndarray, activation:str, num_labels: int, architecture:list[int]):\n",
        "    self.X = normalize(X)\n",
        "    self.X_test = normalize(X_test)\n",
        "    self.y, self.y_test = y.copy(), y_test.copy()\n",
        "    self.architecture = architecture\n",
        "    self.activation = activation\n",
        "    self.num_labels = num_labels\n",
        "    self.parameters = {}\n",
        "    self.m = X.shape[1]\n",
        "    self.architecture.append(self.num_labels)\n",
        "    self.num_input_features = X.shape[0]\n",
        "    self.architecture.insert(0, self.num_input_features)\n",
        "    self.L = len(self.architecture)\n",
        "    self.layers = {}\n",
        "\n",
        "    assert self.X.shape == (self.num_input_features, self.m)\n",
        "    assert self.y.shape == (self.num_labels, self.m)\n",
        "\n",
        "  def initialize_parameters(self):\n",
        "    for i in range (1, self.L):\n",
        "      print(f\"Initializing parameters for layer:{i}.\")\n",
        "      self.parameters[\"w\"+str(i)] = np.random.randn(self.architecture[i], self.architecture[i-1]) * 0.01\n",
        "      self.parameters[\"b\"+str(i)] = np.zeros((self.architecture[i], 1))\n",
        "\n",
        "  def forward(self):\n",
        "    params = self.parameters\n",
        "    self.layers[\"a0\"] = self.X\n",
        "    for l in range(1, self.L - 1):\n",
        "      self.layers[\"z\" + str(l)] = np.dot(params[\"w\" + str(l)], self.layers[\"a\" + str(l - 1)]) + params[\"b\" + str(l)]\n",
        "      self.layers[\"a\" + str(l)] = eval(self.activation)(self.layers[\"z\" + str(l)])\n",
        "      assert self.layers[\"a\" + str(l)].shape == (self.architecture[l], self.m)\n",
        "\n",
        "    self.layers[\"z\" + str(self.L - 1)] = np.dot(params[\"w\" + str(self.L - 1)], self.layers[\"a\" + str(self.L - 2)]) + params[\"b\" + str(self.L - 1)]\n",
        "    self.layers[\"a\" + str(self.L - 1)] = softmax(self.layers[\"z\" + str(self.L - 1)])\n",
        "    self.output = self.layers[\"a\" + str(self.L - 1)]\n",
        "\n",
        "    assert self.output.shape == (self.num_labels, self.m)\n",
        "\n",
        "    cost = - np.sum(self.y * np.log(self.output + 1e-10)) / self.m\n",
        "\n",
        "    return cost, self.layers\n",
        "\n",
        "  def backpropagate(self):\n",
        "    derivatives = {}\n",
        "    dZ = self.output - self.y\n",
        "    assert dZ.shape == (self.num_labels, self.m)\n",
        "\n",
        "    dW = np.dot(dZ, self.layers[\"a\" + str(self.L - 2)].T) / self.m\n",
        "    db = np.sum(dZ, axis=1, keepdims=True) / self.m\n",
        "    dAPrev = np.dot(self.parameters[\"w\" + str(self.L - 1)].T, dZ)\n",
        "\n",
        "    derivatives[\"dW\" + str(self.L - 1)] = dW\n",
        "    derivatives[\"db\" + str(self.L - 1)] = db\n",
        "\n",
        "    for l in range(self.L - 2, 0, -1):\n",
        "      dZ = dAPrev * derivative(self.activation, self.layers[\"z\" + str(l)])\n",
        "      dW = 1. / self.m * np.dot(dZ, self.layers[\"a\" + str(l - 1)].T)\n",
        "      db = 1. / self.m * np.sum(dZ, axis=1, keepdims=True)\n",
        "      if l > 1:\n",
        "        dAPrev = np.dot(self.parameters[\"w\" + str(l)].T, (dZ))\n",
        "      derivatives[\"dW\" + str(l)] = dW\n",
        "      derivatives[\"db\" + str(l)] = db\n",
        "    self.derivatives = derivatives\n",
        "\n",
        "    return self.derivatives\n",
        "\n",
        "  def fit(self, lr=0.01, epochs=1000):\n",
        "    self.costs = []\n",
        "    self.initialize_parameters()\n",
        "    self.accuracies = {\"train\": [], \"test\": []}\n",
        "    for epoch in tqdm(range(epochs), colour=\"BLUE\"):\n",
        "      cost, cache = self.forward()\n",
        "      self.costs.append(cost)\n",
        "      derivatives = self.backpropagate()\n",
        "      for layer in range(1, self.L):\n",
        "        self.parameters[\"w\"+str(layer)] = self.parameters[\"w\"+str(layer)] - lr * derivatives[\"dW\" + str(layer)]\n",
        "        self.parameters[\"b\"+str(layer)] = self.parameters[\"b\"+str(layer)] - lr * derivatives[\"db\" + str(layer)]\n",
        "      train_accuracy = self.accuracy(self.X, self.y)\n",
        "      test_accuracy = self.accuracy(self.X_test, self.y_test)\n",
        "      if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch:3d} | Cost: {cost:.3f} | Train Accuracy: {train_accuracy:.3f} | Test Accuracy: {test_accuracy:.3f}\")\n",
        "      self.accuracies[\"train\"].append(train_accuracy)\n",
        "      self.accuracies[\"test\"].append(test_accuracy)\n",
        "    print(\"Training has terminated\")\n",
        "\n",
        "  def predict(self, x):\n",
        "    params = self.parameters\n",
        "    n_layers = self.L - 1\n",
        "    values = [x]\n",
        "    for l in range(1, n_layers):\n",
        "      z = np.dot(params[\"w\" + str(l)], values[l-1]) + params[\"b\" + str(l)]\n",
        "      a = eval(self.activation)(z)\n",
        "      values.append(a)\n",
        "    z = np.dot(params[\"w\"+str(n_layers)], values[n_layers-1]) + params[\"b\"+str(n_layers)]\n",
        "    a = softmax(z)\n",
        "\n",
        "    if x.shape[1] > 1:\n",
        "      ans = np.argmax(a, axis=0)\n",
        "    else:\n",
        "      ans = np.argmax(a)\n",
        "    return ans\n",
        "\n",
        "  def accuracy(self, X, y):\n",
        "    P = self.predict(X)\n",
        "    return np.mean(np.equal(P, np.argmax(y, axis=0))) * 100"
      ],
      "metadata": {
        "id": "W-K01-z8GEXE"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXU5s8ySIQeV",
        "outputId": "9606edf1-efed-47ed-fb38-9514e6a888be"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.NN"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def intialize_parameters(self):\n",
        "  for i in range (1,self.l):\n",
        "    print(f\"Initializing parameters for layer:{i}.\")\n",
        "    self.parameters[\"w\"+str(i)] = np.random.randn(self.architecture[i],self.architecture[i-1])*0.01\n",
        "    self.parameters[\"b\"+str(i)] = np.zeros(self.architecture[i],1)"
      ],
      "metadata": {
        "id": "S1ycZpDp7vR3"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEEDFORWAD"
      ],
      "metadata": {
        "id": "uZFCFBzgBeJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self):\n",
        "        params=self.parameters\n",
        "        self.layers[\"a0\"] = self.X\n",
        "        for l in range(1, self.L-1):\n",
        "            self.layers[\"z\" + str(l)] = np.dot(params[\"w\" + str(l)],\n",
        "                                               self.layers[\"a\"+str(l-1)]) + params[\"b\"+str(l)]\n",
        "            self.layers[\"a\" + str(l)] = eval(self.activation)(self.layers[\"z\"+str(l)])\n",
        "            assert self.layers[\"a\"+str(l)].shape == (self.architecture[l], self.m)\n",
        "        self.layers[\"z\" + str(self.L-1)] = np.dot(params[\"w\" + str(self.L-1)],\n",
        "                                                  self.layers[\"a\"+str(self.L-2)]) + params[\"b\"+str(self.L-1)]\n",
        "        self.layers[\"a\"+str(self.L-1)] = softmax(self.layers[\"z\"+str(self.L-1)])\n",
        "        self.output = self.layers[\"a\"+str(self.L-1)]\n",
        "        assert self.output.shape == (self.num_labels, self.m)\n",
        "        assert all([s for s in np.sum(self.output, axis=1)])\n",
        "\n",
        "        cost = - np.sum(self.y * np.log(self.output + 0.000000001))\n",
        "\n",
        "        return cost, self.layers"
      ],
      "metadata": {
        "id": "KveHDvs9BkrI"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BACKPROPAGATION"
      ],
      "metadata": {
        "id": "voWYe2DNC0Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backpropagate(self):\n",
        "        derivatives = {}\n",
        "        dZ = self.output - self.y\n",
        "        assert dZ.shape == (self.num_labels, self.m)\n",
        "        dW = np.dot(dZ, self.layers[\"a\" + str(self.L-2)].T) / self.m\n",
        "        db = np.sum(dZ, axis=1, keepdims=True) / self.m\n",
        "        dAPrev = np.dot(self.parameters[\"w\" + str(self.L-1)].T, dZ)\n",
        "        derivatives[\"dW\" + str(self.L-1)] = dW\n",
        "        derivatives[\"db\" + str(self.L-1)] = db\n",
        "\n",
        "        for l in range(self.L-2, 0, -1):\n",
        "            dZ = dAPrev * derivative(self.activation, self.layers[\"z\" + str(l)])\n",
        "            dW = 1. / self.m * np.dot(dZ, self.layers[\"a\" + str(l-1)].T)\n",
        "            db = 1. / self.m * np.sum(dZ, axis=1, keepdims=True)\n",
        "            if l > 1:\n",
        "                dAPrev = np.dot(self.parameters[\"w\" + str(l)].T, (dZ))\n",
        "            derivatives[\"dW\" + str(l)] = dW\n",
        "            derivatives[\"db\" + str(l)] = db\n",
        "        self.derivatives = derivatives\n",
        "\n",
        "        return self.derivatives"
      ],
      "metadata": {
        "id": "o1kFbMfdC0t0"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting, accuracy, and predictions"
      ],
      "metadata": {
        "id": "4tthMlUJC6lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(self, lr=0.01, epochs=1000):\n",
        "        self.costs = []\n",
        "        self.initialize_parameters()\n",
        "        self.accuracies = {\"train\": [], \"test\": []}\n",
        "        for epoch in tqdm(range(epochs), colour=\"BLUE\"):\n",
        "            cost, cache = self.forward()\n",
        "            self.costs.append(cost)\n",
        "            derivatives = self.backpropagate()\n",
        "            for layer in range(1, self.L):\n",
        "                self.parameters[\"w\"+str(layer)] = self.parameters[\"w\"+str(layer)] - lr * derivatives[\"dW\" + str(layer)]\n",
        "                self.parameters[\"b\"+str(layer)] = self.parameters[\"b\"+str(layer)] - lr * derivatives[\"db\" + str(layer)]\n",
        "            train_accuracy = self.accuracy(self.X, self.y)\n",
        "            test_accuracy = self.accuracy(self.X_test, self.y_test)\n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"Epoch: {epoch:3d} | Cost: {cost:.3f} | Accuracy: {train_accuracy:.3f}\")\n",
        "            self.accuracies[\"train\"].append(train_accuracy)\n",
        "            self.accuracies[\"test\"].append(test_accuracy)\n",
        "        print(\"Training terminated\")"
      ],
      "metadata": {
        "id": "3ql2JMYqC8AP"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(self, x):\n",
        "        params = self.parameters\n",
        "        n_layers = self.L - 1\n",
        "        values = [x]\n",
        "        for l in range(1, n_layers):\n",
        "            z = np.dot(params[\"w\" + str(l)], values[l-1]) + params[\"b\" + str(l)]\n",
        "            a = eval(self.activation)(z)\n",
        "            values.append(a)\n",
        "        z = np.dot(params[\"w\"+str(n_layers)], values[n_layers-1]) + params[\"b\"+str(n_layers)]\n",
        "        a = softmax(z)\n",
        "        if x.shape[1]>1:\n",
        "            ans = np.argmax(a, axis=0)\n",
        "        else:\n",
        "            ans = np.argmax(a)\n",
        "        return ans\n",
        "\n",
        "\n",
        "def accuracy(self, X, y):\n",
        "    P = self.predict(X)\n",
        "    return sum(np.equal(P, np.argmax(y, axis=0))) / y.shape[1]*100"
      ],
      "metadata": {
        "id": "bjI5GytBC_00"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_split_no = 60000\n",
        "X_train = data.values[:train_test_split_no].T\n",
        "y_train = labels[:train_test_split_no].values.astype(int)\n",
        "y_train = one_hot_encode(y_train, 10).T\n",
        "X_test = data.values[train_test_split_no:].T\n",
        "y_test = labels[train_test_split_no:].values.astype(int)\n",
        "y_test = one_hot_encode(y_test, 10).T\n",
        "X_train.shape, X_test.shape\n",
        "((784, 60000), (784, 10000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FmBJClmDDBt",
        "outputId": "ef01e118-f459-4c5e-b2cf-ad989f13c9f8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((784, 60000), (784, 10000))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PARAMS = [X_train, y_train, X_test, y_test, \"relu\", 10, [128, 32]]\n",
        "nn_relu = NN(*PARAMS)\n",
        "epochs_relu = 80\n",
        "lr_relu = 0.003\n",
        "nn_relu.fit(lr=lr_relu, epochs=epochs_relu) # Removed X_train, y_train arguments\n",
        "# nn_relu.plot_cost(lr_relu) # Commented out as plot_cost method is not defined in the class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzBMGm7iDFto",
        "outputId": "cfd6c37d-d28c-4ad9-bd7b-34952f6a858d"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing parameters for layer:1.\n",
            "Initializing parameters for layer:2.\n",
            "Initializing parameters for layer:3.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|\u001b[34m▏         \u001b[0m| 1/80 [00:01<02:15,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   0 | Cost: 13.305 | Train Accuracy: 12.650 | Test Accuracy: 12.560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|\u001b[34m█▍        \u001b[0m| 11/80 [00:21<02:11,  1.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  10 | Cost: 13.305 | Train Accuracy: 12.945 | Test Accuracy: 12.930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|\u001b[34m██▋       \u001b[0m| 21/80 [00:39<01:42,  1.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  20 | Cost: 13.305 | Train Accuracy: 11.893 | Test Accuracy: 11.850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|\u001b[34m███▉      \u001b[0m| 31/80 [00:59<01:41,  2.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  30 | Cost: 13.305 | Train Accuracy: 11.340 | Test Accuracy: 11.380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|\u001b[34m█████▏    \u001b[0m| 41/80 [01:17<01:10,  1.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  40 | Cost: 13.305 | Train Accuracy: 11.245 | Test Accuracy: 11.350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|\u001b[34m██████▍   \u001b[0m| 51/80 [01:35<00:49,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  50 | Cost: 13.305 | Train Accuracy: 11.237 | Test Accuracy: 11.350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|\u001b[34m███████▋  \u001b[0m| 61/80 [01:54<00:36,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  60 | Cost: 13.305 | Train Accuracy: 11.237 | Test Accuracy: 11.350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|\u001b[34m████████▉ \u001b[0m| 71/80 [02:13<00:16,  1.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  70 | Cost: 13.305 | Train Accuracy: 11.237 | Test Accuracy: 11.350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u001b[34m██████████\u001b[0m| 80/80 [02:30<00:00,  1.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training terminated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}
